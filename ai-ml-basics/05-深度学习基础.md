# 深度学习基础

## 📋 什么是深度学习？

**深度学习（Deep Learning）**是机器学习的一个子集，使用多层神经网络来学习数据的表示。

## 🎯 核心概念

### 神经网络

**人工神经网络**：模拟人脑神经元的计算模型

```
输入层 → 隐藏层1 → 隐藏层2 → ... → 输出层
```

### 神经元（Neuron）

```python
# 神经元计算
output = activation_function(Σ(weight_i * input_i) + bias)
```

### 激活函数

- **Sigmoid**：σ(x) = 1 / (1 + e^(-x))
- **ReLU**：f(x) = max(0, x)
- **Tanh**：tanh(x)
- **Softmax**：用于多分类

## 🏗️ 网络架构

### 1. 前馈神经网络（Feedforward Neural Network）

```
输入 → 隐藏层 → 输出
```

### 2. 卷积神经网络（CNN）

**特点**：
- 卷积层：提取局部特征
- 池化层：降维
- 全连接层：分类

**应用**：
- 图像识别
- 计算机视觉

### 3. 循环神经网络（RNN）

**特点**：
- 处理序列数据
- 有记忆能力

**变体**：
- LSTM：长短期记忆
- GRU：门控循环单元

**应用**：
- 自然语言处理
- 时间序列预测

### 4. Transformer

**特点**：
- 注意力机制
- 并行处理
- 长距离依赖

**应用**：
- 大语言模型
- 机器翻译

## 🔧 训练过程

### 1. 前向传播

```python
# 计算输出
def forward(x):
    h1 = relu(W1 @ x + b1)
    h2 = relu(W2 @ h1 + b2)
    output = softmax(W3 @ h2 + b3)
    return output
```

### 2. 损失函数

- **均方误差（MSE）**：回归任务
- **交叉熵（Cross Entropy）**：分类任务

### 3. 反向传播

```python
# 计算梯度
loss.backward()

# 更新参数
optimizer.step()
```

### 4. 优化器

- **SGD**：随机梯度下降
- **Adam**：自适应矩估计
- **RMSprop**：均方根传播

## 💡 代码示例

```python
import torch
import torch.nn as nn
import torch.optim as optim

# 定义网络
class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# 创建模型
model = SimpleNet()

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练循环
for epoch in range(10):
    for batch_x, batch_y in dataloader:
        # 前向传播
        outputs = model(batch_x)
        loss = criterion(outputs, batch_y)
        
        # 反向传播
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

## 🎯 应用领域

### 1. 计算机视觉
- 图像分类
- 目标检测
- 图像生成

### 2. 自然语言处理
- 文本分类
- 机器翻译
- 文本生成

### 3. 语音识别
- 语音转文字
- 语音合成

### 4. 推荐系统
- 个性化推荐
- 内容推荐

## ⚡ 优势

- ✅ **自动特征提取**：不需要手工设计特征
- ✅ **处理复杂数据**：图像、文本、语音
- ✅ **端到端学习**：从输入到输出直接学习

## ⚠️ 挑战

- ❌ **需要大量数据**：训练需要大量标注数据
- ❌ **计算资源**：需要 GPU 等硬件
- ❌ **黑盒问题**：难以解释模型决策
- ❌ **过拟合风险**：容易过拟合

## 🔗 相关概念

- **反向传播**：计算梯度的方法
- **梯度下降**：优化算法
- **正则化**：防止过拟合
- **Dropout**：随机失活
- **Batch Normalization**：批归一化

---

*最后更新：2024年*
